# База знаний по AI/NLP/LLM

## Введение в языковые модели

Основные концепции и архитектуры современных языковых моделей. Теоретические основы и историческое развитие технологий NLP.

### [Документация OpenAI по embeddings](https://openai-docs.ru/docs/guides/embeddings)

Руководство по работе с векторными представлениями слов и текстов. Объясняет принципы генерации и использования эмбеддингов в NLP-задачах, включая семантический поиск и кластеризацию текстов.

### [Введение в большие языковые модели (LLM)](https://www.youtube.com/watch?v=HEgoPEppu7A)

Видеолекция, охватывающая базовые принципы работы LLM: архитектуру трансформеров, механизмы внимания и процесс предобучения моделей.

### [Архитектура Encoder-Decoder](https://cloudskillsboost.google/course_templates/543)

Курс Google Cloud об архитектурных решениях в современных NLP-системах. Подробно рассматривается принцип разделения кодирования и декодирования в задачах машинного перевода и генерации текста.

## Методы обучения моделей

Техники адаптации и улучшения производительности языковых моделей под конкретные задачи.

### [Fine-tuning моделей](https://platform.openai.com/docs/guides/fine-tuning)

Официальное руководство OpenAI по дообучению моделей. Описывает процесс подготовки данных, выбор гиперпараметров и оценку результатов тонкой настройки.

### [Технология RAG](https://habr.com/ru/companies/wunderfund/articles/779748/)

Retrieval-Augmented Generation - метод объединения поисковых систем с генеративными моделями. Включает практические примеры реализации и сравнение с другими подходами.

### [Обучение с подкреплением (RLHF)](https://habr.com/ru/companies/wunderfund/articles/731128/)
Практическое руководство по использованию обратной связи человека для улучшения поведения моделей. На примере LLaMA показаны этапы сбора данных и процесс оптимизации.

## Инструменты и платформы
Программные решения для разработки и развертывания AI-систем.

### [LangChain](https://github.com/langchain-ai/langchain)
Фреймворк для создания цепочек обработки естественного языка. Поддерживает интеграцию с различными LLM и внешними источниками данных.

### [Ollama](https://ollama.ai/)
Платформа для локального запуска языковых моделей. Позволяет работать с популярными архитектурами (Llama, Mistral) без использования облачной инфраструктуры.

### [vLLM](https://vllm.ai/)
Оптимизированная библиотека для ускорения инференса больших моделей. Особенности: эффективное управление памятью, пакетная обработка запросов.

## Практические применения
Кейсы использования языковых моделей в реальных проектах.

### [Диалоговые системы](https://rasa.com/product/rasa-platform/)
Платформа Rasa для создания контекстно-зависимых чат-ботов. Обзор архитектуры, инструментов разработки и best practices.

### [Обработка аудио](https://github.com/openai/whisper)
Модель Whisper для транскрибации и перевода речи. Руководство по интеграции с системами диарализации (пример: Pyannote).

### [Корпоративные знания](https://habr.com/ru/companies/raft/articles/863888/)
Реализация систем поиска по документам с использованием RAG. Особенности: векторизация контента, семантический поиск, оценка качества.

## Оптимизация и производительность
Методы улучшения эффективности работы LLM.

### [Ускорение инференса](https://habr.com/ru/companies/yandex/articles/878230/)
Техники оптимизации от Яндекса: квантование моделей, аппаратные ускорение, эффективное использование памяти.

### [Выбор GPU](https://vc.ru/ai/881777-spravochnik-po-vyboru-gpu-dlya-raboty-s-bolshimi-yazykovymi-modelyami-llama)
Рекомендации по подбору оборудования для обучения и запуска LLM. Сравнение производительности разных видеокарт.

## Дополнительные ресурсы
### [Awesome LLM Agents](https://github.com/kaushikb11/awesome-llm-agents)
Коллекция инструментов для разработки агентов на базе языковых моделей. Включает фреймворки, библиотеки и исследовательские работы.

### [Prompt Engineering Guide](https://www.promptingguide.ai/ru)
Исчерпывающее руководство по техникам промпт-инжиниринга. Примеры эффективных промптов для разных типов задач.
