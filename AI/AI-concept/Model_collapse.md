---
aliases:
  - Model collapse
up:
  - [[AI-concept]]
---
## Model collapse


https://www.techtarget.com/whatis/feature/Model-collapse-explained-How-synthetic-training-data-breaks-AI
Model collapse explained: How synthetic training data breaks AI
Without human-generated training data, AI systems malfunction. This could be a problem if the internet becomes flooded with AI-generated content.
Garbage in, garbage out. Data pollution is ruining generative AI's future.
A recent study by researchers in Canada and the U.K. explained the phenomenon of model collapse. Model collapse occurs when new generative models train on [AI-generated content](https://www.techtarget.com/whatis/feature/Pros-and-cons-of-AI-generated-content) and gradually degenerate as a result.

![[arxiv--2023-08-16_19-25.webp]]
https://arxiv.org/abs/2305.17493
cs > arXiv:2305.17493
Computer Science > Machine Learning
(Submitted on 27 May 2023 (v1), last revised 31 May 2023 (this version, v2))
The Curse of Recursion: Training on Generated Data Makes Models Forget
Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, Ross Anderson

.... We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of content generated by LLMs in data crawled from the Internet.

