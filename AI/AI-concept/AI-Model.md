---
aliases:
  - Model (AI)
  - AI model
  - ИИ Модель
  - Нейросеть (ИИ)
up:
  - [[AI-concept]]
---
up:  [[AI-concept]]
# Model (in AI)

[[#AI major model types]] (below)
[[AI-Model-Sizes]]

## AI major model types
Виды моделей

Generative Models
  **LLMs** (Large Language Models) --> [[AI-concept#LLM]]
  **Text-to-Image Models** - generate images from textual descriptions.
  **Image-to-Image** Models

Foundation Models  -  Foundation models are machine learning models pre-trained to perform tasks. --> [[AI-Model#Foundation models]]
Multimodal LLMs -> [[Log-2024#Multimodal LLMs]] 
**Other** AI model types -> [[#Other AI model types]]

### LLM - Large Language Model
See: [[LLM]]
#### Multimodal LLMs
multimodal LLM is an AI system trained with multiple modes of data. For instance, existing multimodal LLM are trained on image, text, and audio data.

### Foundation models
#### Large foundation models, LFM
Фундаментальные модель

https://research.ibm.com/blog/what-are-foundation-models

https://en.wikipedia.org/wiki/Foundation_models
A foundation model (also called base model)[1] is a large machine learning (ML) model trained on a vast quantity of data at scale (often by self-supervised learning or semi-supervised learning)[2] resulting in a model that can be adapted to a wide range of downstream tasks.[3][4] Foundation models have helped bring about a major transformation in how AI systems are built, such as by powering prominent chatbots and other user-facing AI. The Stanford Institute for Human-Centered Artificial Intelligence's (HAI) Center for Research on Foundation Models (CRFM) popularized the term.[3]


### text-to-image model 
Aliases: txt2img
https://en.wikipedia.org/wiki/Text-to-image_model
A **text-to-image** model is a [machine learning](https://en.wikipedia.org/wiki/Machine_learning "Machine learning") model which takes an input [natural language](https://en.wikipedia.org/wiki/Natural_language "Natural language") description and produces an image matching that description. Such models began to be developed in the mid-2010s, as a result of advances in [deep neural networks](https://en.wikipedia.org/wiki/Deep_learning "Deep learning"). In 2022, the output of state of the art text-to-image models, such as OpenAI's [DALL-E 2](https://en.wikipedia.org/wiki/DALL-E_2 "DALL-E 2"), Google Brain's [Imagen](https://en.wikipedia.org/wiki/Imagen_(Google_Brain) "Imagen (Google Brain)") and StabilityAI's [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion "Stable Diffusion") began to approach the quality of real photographs and human-drawn art.



## Other AI model types
from Google Gemini:

**Discriminative Models**
- **Image Classification Models:** These models classify images into different categories. Examples include ResNet and VGG.  
- **Object Detection Models:** These models identify and locate objects within an image. Examples include YOLO and Faster R-CNN.  
- **Natural Language Processing (NLP) Models:** These models process and understand human language. Examples include BERT and GPT-3 (before it was fine-tuned as an LLM).  

**Other Types**
- **Reinforcement Learning Models:** These models learn to make decisions by interacting with an environment and receiving rewards or penalties. Examples include AlphaGo and OpenAI Five.  
- **Recommender Systems:** These models recommend products or content to users based on their past behavior. Examples include collaborative filtering and content-based filtering.  
