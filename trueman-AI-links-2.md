# База знаний по ИИ, NLP и LLM

## Основы и концепции

### Большие языковые модели (LLM)

- [Что такое большие языковые модели (LLM)?](https://www.techtarget.com/whatis/definition/large-language-model-LLM) - Объяснение концепции больших языковых моделей и их применения.
- [Википедия: Большая языковая модель](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%B0%D1%8F_%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C) - Статья о больших языковых моделях на русском языке.
- [Wikipedia: Large language model](https://en.wikipedia.org/wiki/Large_language_model) - Статья о больших языковых моделях на английском языке.
- [LLM field landscape](https://habr.com/ru/articles/814665/) - Обзор актуальных концептов, задач, проблем и исследований, связанных с Large Language Models (LLM) и Language Modeling (LM) на 2024 год.

### Обработка естественного языка (NLP)

- [Что такое NLP (обработка естественного языка)?](https://www.ibm.com/topics/natural-language-processing) - Обзор концепции обработки естественного языка и ее применений.

### Трансформеры

- [Википедия: Трансформер (модель машинного обучения)](https://ru.wikipedia.org/wiki/%D0%A2%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B5%D1%80_(%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C_%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)) - Статья о архитектуре трансформеров.
- [Объясняем простым языком, что такое трансформеры](https://habr.com/ru/companies/mws/articles/770202/) - Простое объяснение концепции трансформеров.
- [Аритектура моделей Трансформер (Яндекс Образование)](https://education.yandex.ru/handbook/ml/article/transformery) - Подробное описание архитектуры трансформеров.
- [Transformer в картинках](https://habr.com/ru/articles/486358/) - Визуальное объяснение работы трансформеров.
- [Визуализируя нейронный машинный перевод (seq2seq модели с механизмом внимания)](https://habr.com/ru/articles/486158/) - Визуализация работы моделей seq2seq с механизмом внимания.

### Промпт-инжиниринг

- [Руководство по промпт-инжинирингу](https://www.promptingguide.ai/ru) - Подробное руководство по техникам промпт-инжиниринга.
- [Википедия: Техника подсказок](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%B8%D0%BA%D0%B0_%D0%BF%D0%BE%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%BE%D0%BA) - Статья о технике подсказок (промпт-инжиниринге) на русском языке.
- [Wikipedia: Prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering) - Статья о промпт-инжиниринге на английском языке.
- [FlexiPrompt: Удобное создание динамических промптов в Python](https://habr.com/ru/articles/854560/) - Статья о создании динамических промптов с использованием Python.

### Обучение с подкреплением (RL)

- [LLM with RL papers](https://github.com/floodsung/LLM-with-RL-papers) - Коллекция статей о комбинации больших языковых моделей с обучением с подкреплением.

### Другие концепции

- [Что такое fine-tuning?](https://www.ibm.com/topics/fine-tuning) - Объяснение концепции тонкой настройки моделей машинного обучения.
- [Что такое Transfer Learning?](https://www.tasq.ai/glossary/transfer-learning/) - Объяснение концепции трансферного обучения.
- [Что такое Few-Shot Learning?](https://www.ibm.com/topics/few-shot-learning) - Объяснение концепции обучения по нескольким примерам.
- [N-shot learning и context learning](https://artificial-intuition.beehiiv.com/p/few-shot-learning-context-learning) - Объяснение концепций N-shot learning и context learning.
- [Википедия: Fine-tuning в глубоком обучении](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)) - Статья о fine-tuning в контексте глубокого обучения.

## Техники и методы

### Внимание и рассуждение

- [LLM Reasoning](https://www.promptingguide.ai/research/llm-reasoning) - Исследование способностей LLM к рассуждению.
- [Awesome LLM Reasoning](https://github.com/atfortes/Awesome-LLM-Reasoning) - Коллекция ресурсов по рассуждению в LLM.

### Квантование

- [Сравнение различных схем квантования для LLM](https://habr.com/ru/articles/797443/) - Обзор методов квантования для больших языковых моделей.

### Retrieval Augmented Generation (RAG)

- [Retrieval Augmented Generation (RAG)](https://www.promptingguide.ai/techniques/rag) - Объяснение техники RAG.
- [Архитектура RAG: часть вторая — Advanced RAG](https://habr.com/ru/companies/raft/articles/818781/) - Углубленное рассмотрение архитектуры RAG.
- [Архитектура RAG: полный гайд](https://habr.com/ru/companies/raft/articles/791034/) - Подробное руководство по архитектуре RAG.
- [Добавление собственных данных в LLM с помощью RAG](https://habr.com/ru/companies/wunderfund/articles/779748/) - Практическое применение RAG для расширения знаний LLM.

### Другие техники

- [Как сделать контекстное окно на 100K в большой языковой модели: обо всех фокусах в одном посте](https://habr.com/ru/articles/752062/) - Техники увеличения контекстного окна в LLM.
- [Эмбеддинги для начинающих](https://habr.com/ru/companies/otus/articles/787116/) - Введение в концепцию эмбеддингов.
- [От слов к векторам: как эмбеддинги помогают моделям понимать нас](https://blogs.epsilonmetrics.ru/kak-embeddingi-pomogayut-llm-ponyat-nas/) - Объяснение роли эмбеддингов в понимании естественного языка.
- [An intuitive introduction to text embeddings](https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/) - Интуитивное введение в текстовые эмбеддинги.
- [How to Train a Custom LLM Embedding Model (Python)](https://dagshub.com/blog/how-to-train-a-custom-llm-embedding-model/) - Руководство по обучению собственной модели эмбеддингов.
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://github.com/artidoro/qlora) - Эффективный метод тонкой настройки квантованных LLM.

## Модели и инструменты

### Популярные модели

- [7 Language Models You Need to Know](https://aibusiness.com/nlp/7-language-models-you-need-to-know) - Обзор семи важнейших языковых моделей.
- [LLaMA (language model)](https://en.wikipedia.org/wiki/Llama_(language_model)) - Информация о модели LLaMA от Meta AI.
- [LaMDA](https://en.wikipedia.org/wiki/LaMDA) - Информация о семействе диалоговых LLM от Google.
- [Gemini (language model)](https://en.wikipedia.org/wiki/Gemini_(language_model)) - Информация о модели Gemini от Google DeepMind.
- [Mamba — LLM-модель. От начала до конца](https://habr.com/ru/articles/786278/) - Обзор модели Mamba.
- [Mixtral of experts](https://mistral.ai/news/mixtral-of-experts/) - Информация о модели Mixtral, использующей подход "смесь экспертов".
- [Microsoft Research выпустила Orca 2 LLM, способную сравниться по производительности с крупными моделями](https://habr.com/ru/news/776562/) - Новость о выпуске модели Orca 2.
- [Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs](https://www.databricks.com/blog/mpt-7b) - Представление модели MPT-7B.
- [Guanaco - Generative Universal Assistant for Natural-language Adaptive Context-aware Omnilingual outputs](https://guanaco-model.github.io/) - Информация о модели Guanaco, основанной на LLaMA.
- [Phi-2: a 2.7B language model by Microsoft Research](https://ollama.com/library/phi) - Информация о модели Phi-2 от Microsoft Research.
- [LLM от xAI (компания Маска)](https://x.ai/) - Информация о языковой модели от компании xAI.

### Инструменты и фреймворки

- [LangChain](https://python.langchain.com/docs/introduction/) - Фреймворк для разработки приложений на основе LLM.
- [Hugging Face](https://huggingface.co/) - Платформа для работы с моделями машинного обучения.
- [OpenAI API](https://platform.openai.com/docs/api-reference) - Документация по API OpenAI.
- [Whisper: open-sourcing speech recognition model](https://openai.com/index/whisper/) - Модель для распознавания речи от OpenAI.
- [Ollama](https://ollama.com/) - Фреймворк для локального запуска и управления LLM.
- [LM Studio](https://lmstudio.ai/) - Инструмент для запуска LLM на локальных устройствах.
- [Jan](https://jan.ai/) - Открытая платформа для работы с LLM локально.
- [Text generation web UI](https://github.com/oobabooga/text-generation-webui) - Веб-интерфейс для генерации текста с использованием LLM.
- [LibreChat](https://www.librechat.ai/) - Открытая платформа для общения с ИИ.
- [OpenRouter](https://openrouter.ai/) - Унифицированный интерфейс для работы с различными LLM.
- [GPT4All](https://www.nomic.ai/gpt4all) - Решение для запуска открытых моделей ИИ на локальных устройствах.
- [Huginn](https://github.com/huginn/huginn) - Платформа для автоматизации задач в интернете с использованием агентов.
- [Character.ai](https://character.ai/) - Веб-сайт с ИИ-ассистентами.
- [Powerful AI Tools Directory](https://www.powerfulai.tools/?filter=Free) - Каталог различных (в том числе бесплатных) AI-инструментов.

### Инфраструктура и развертывание

- [Типы инференса ML моделей](https://ml-system-design.ru/blog/inference/%D1%82%D0%B8%D0%BF%D1%8B-%D0%B8%D0%BD%D1%84%D0%B5%D1%80%D0%B5%D0%BD%D1%81%D0%B0-ml-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B5%D0%B9) - Обзор различных типов инференса ML моделей.
- [Model Server: A Key Component of MLOps](https://www.axelmendoza.com/posts/model-server/) - Объяснение роли Model Server в MLOps.
- [Что такое MLOps?](https://habr.com/ru/companies/selectel/articles/703460/) - Подробное объяснение концепции MLOps.
- [Groq](https://groq.com/) - Платформа для быстрого инференса AI моделей.
- [Databricks](https://www.databricks.com/) - Облачная платформа для обработки данных, аналитики и искусственного интеллекта.
- [Paperspace](https://paperspace.com) - Облачная платформа для AI и машинного обучения, запуска Jupyter notebooks.
- [Википедия: Инфраструктура как код](https://ru.wikipedia.org/wiki/Инфраструктура_как_код) - Статья об инфраструктуре как коде.
- [Terraform](https://habr.com/ru/companies/piter/articles/351878/) — Статья на Хабре про Terraform

